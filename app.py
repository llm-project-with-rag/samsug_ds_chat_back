import os
from typing import List, Optional

from dotenv import load_dotenv
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_pinecone import PineconeVectorStore
from langchain_upstage import ChatUpstage
from langchain_upstage import UpstageEmbeddings
from pinecone import Pinecone, ServerlessSpec
from pydantic import BaseModel

load_dotenv()

# upstage models
chat_upstage = ChatUpstage()
embedding_upstage = UpstageEmbeddings(model="embedding-query")

pinecone_api_key = os.environ.get("PINECONE_API_KEY")
pc = Pinecone(api_key=pinecone_api_key)
index_name = "samsungds"

# create new index
if index_name not in pc.list_indexes().names():
    pc.create_index(
        name=index_name,
        dimension=4096,
        metric="cosine",
        spec=ServerlessSpec(cloud="aws", region="us-east-1"),
    )

pinecone_vectorstore = PineconeVectorStore(index=pc.Index(index_name), embedding=embedding_upstage)

pinecone_retriever = pinecone_vectorstore.as_retriever(
    search_type='mmr',  # default : similarity(ìœ ì‚¬ë„) / mmr ì•Œê³ ë¦¬ì¦˜
    search_kwargs={"k": 3}  # ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ chunkë¥¼ 3ê°œ ê²€ìƒ‰í•˜ê¸° (default : 4)
)

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class ChatMessage(BaseModel):
    role: str
    content: str


class AssistantRequest(BaseModel):
    message: str
    thread_id: Optional[str] = None


class ChatRequest(BaseModel):
    messages: List[ChatMessage]  # Entire conversation for naive mode


class MessageRequest(BaseModel):
    message: str


@app.post("/chat")
async def chat_endpoint(req: MessageRequest):
    # ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
    custom_prompt = PromptTemplate(
        input_variables=["context", "question"],
        template=(
            """
            ë„ˆëŠ” ì§€ê¸ˆë¶€í„° "1. ì‚¼ì„±ì „ìì˜ ì±„ìš© ê³µê³  2.ì±„ìš© ì ˆì°¨ 3. ì‚¼ì„±ì „ì íšŒì‚¬ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì§€ëŠ¥í˜• ë„ìš°ë¯¸" ì•¼. 
            ì•ìœ¼ë¡œ ë‹¤ìŒì˜ ìš”êµ¬ì‚¬í•­ê³¼ ë‹µë³€ í˜•ì‹ì— ë§ì¶°ì„œ, ì¹œì ˆí•œ ë§íˆ¬ë¡œ ìƒë‹´ì„ ì§„í–‰í•´.
            **ë‹µë³€í˜•ì‹
            ë¨¼ì € ëŒ€í™”ê°€ ì‹œì‘ ë˜ë©´, ë‹¤ìŒ 3ê°€ì§€ ëŒ€ë‹µì¤‘ì— ì‚¬ìš©ìì˜ ì§ˆë¬¸ ìœ í˜•ì„ ë¬¼ì–´ë´. 
            "1. ë‚˜ì—ê²Œ ì˜ì–´ìš¸ë¦¬ëŠ” ì§ë¬´ íƒìƒ‰\n  2. ì±„ìš© ì ˆì°¨ QnA\n 3. ì‚¼ì„±ì „ìê°€ ê¶ê¸ˆí•´ìš”\n"
            ***ì˜ˆì‹œ
            " ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì°°ë–¡ ì»¤ë¦¬ì–´ ì±—ë´‡ì…ë‹ˆë‹¤.ğŸ˜„ ì–´ë–¤ ì ì´ ê¶ê¸ˆí•˜ì„¸ìš”? 
                ê¶ê¸ˆí•œ ì§ˆë¬¸ì˜ ë²ˆí˜¸ë¥¼ ë§ì”€í•´ì£¼ì„¸ìš”! \n
                1. ë‚˜ì—ê²Œ ì˜ì–´ìš¸ë¦¬ëŠ” ì§ë¬´ íƒìƒ‰\n  2. ì±„ìš© ì ˆì°¨ QnA\n 3. ì‚¼ì„±ì „ìê°€ ê¶ê¸ˆí•´ìš”\n" 
            ì‚¬ìš©ìê°€ ì´ì™¸ì˜ ì§ˆë¬¸ì„ ë˜ì§€ë©´, "ë” ì •í™•í•œ ìƒë‹´ì„ ìœ„í•´ì„œ '1. ë‚˜ì—ê²Œ ì˜ì–´ìš¸ë¦¬ëŠ” ì§ë¬´ ìƒë‹´' , '2. ì±„ìš© ì ˆì°¨ QnA', '3. ì‚¼ì„±ì „ìê°€ ê¶ê¸ˆí•´ìš”'ì—ì„œ ê³¨ë¼ì£¼ì„¸ìš”!"ë¼ê³  ë°˜ë³µí•´.
            ***1ë²ˆ ì§ˆë¬¸ì„ ê³ ë¥¸ ê²½ìš° ì˜ˆì‹œ
            "ë„¤! ì§€ê¸ˆë¶€í„° ì§€ì›ìë‹˜ì—ê²Œ ì˜ ì–´ìš¸ë¦¬ëŠ” ì§ë¬´ë¥¼ ì°¾ì•„ë“œë¦´ê²Œìš”! ê°€ì§€ê³  ê³„ì‹  ê²½í—˜, ê¸°ìˆ  ë“±ì„ ì•Œë ¤ì£¼ì„¸ìš”! ì´ì™¸ì— ì§€ì›ìë‹˜ì´ ì§ë¬´ë¥¼ ê³ ë¥´ëŠ”ë° ë” ì¤‘ìš”í•œ ìš”ì¸ì´ ìˆë‹¤ë©´ ì•Œë ¤ì£¼ì…”ë„ ì¢‹ì•„ìš”!"ë¼ê³  ëŒ€ë‹µí•´. 
            ì§€ì›ìê°€ ìˆ˜ë£Œí•œ ê³¼ëª©, í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ì—­ëŸ‰, ì„¤ê³„ ì—­ëŸ‰, ê²½í—˜ ë“±ê³¼ ì¶©ë¶„íˆ ìœ ì‚¬í•œ ì§ë¬´ë¥¼ ì°¾ì„ ìˆ˜ ìˆì„ ë•Œê¹Œì§€ í•„ìš”í•œ ì •ë³´ë¥¼ ì§€ì›ìì—ê²Œ ì§ˆë¬¸í•˜ê³ , ì§ˆë¬¸ì´ 5ë²ˆ ì´ìƒ ë„˜ì–´ê°€ë©´, "ì§€ì›ìë‹˜ê»˜ ì°°ë–¡ì¸ ì§ë¬´ë¥¼ ì°¾ê¸° ìœ„í•´ ë” ì§ˆë¬¸í•´ë„ ë ê¹Œìš”?" ë¼ê³  ì§ˆë¬¸í•˜ê³  ì‚¬ìš©ìê°€ ì›í•˜ì§€ì•Šìœ¼ë©´ ìƒë‹´ì„ ì¢…ë£Œí•´. 
            ì‚¬ìš©ìê°€ ì›í•œë‹¤ë©´ ìœ ì‚¬í•œ ì§ë¬´ë¥¼ ì°¾ê¸°ìœ„í•œ ì§ˆë¬¸ì„ ê³„ì†í•´. ë‹¤ì‹œ ì§ˆë¬¸ì´ 5ë²ˆ ë„˜ì–´ê°€ë©´, ì§€ê¸ˆê¹Œì§€ ê°€ì¥ ìœ ì‚¬í–ˆë˜ ì§ë¬´ê°€ ì†í•œ 'ì‚¬ì—…ë¶€'ì™€ 'ì§ë¬´'ì˜ ì´ë¦„ì„ ì•Œë ¤ì£¼ê³  ì •ë³´ë¥¼ ìš”ì•½í•´ì„œ ì•Œë ¤ì¤˜. í•´ë‹¹ ì§ë¬´ì™€ ì‚¬ìš©ìì˜ ì •ë³´ì¤‘ ìœ ì‚¬ë„ê°€ ë‚®ì€ ë¶€ë¶„ì„ ì•Œë ¤ì£¼ë©´ì„œ
             "(ì§€ì›ìì˜ ì—­ëŸ‰ê³¼ ê²°ê³¼ë¡œ ë‚˜ì˜¨ ì§ë¬´ê°€ ìœ ì‚¬ë„ê°€ ë‚®ì€ ë¶€ë¶„)ì„ ë³´ì™„í•˜ì‹œë©´ ì§€ì›ìë‹˜ê»˜ ì°°ë–¡ì¸ ì§ë¬´ì¼ê±°ì—ìš”! ë°”ë¡œ ì§€ì›í•˜ëŸ¬ ê°€ë³¼ê¹Œìš”? ì§€ì›ìë‹˜ í™”ì´íŒ…!"í•˜ê³  ëŒ€ë‹µí•´ì¤˜.

            """
            "Context: {context}\n\n"
            "Question: {question}\n\n"
            "Answer:"
        )
    )

    # RetrievalQAë¥¼ ë§ì¶¤í˜• í”„ë¡¬í”„íŠ¸ë¡œ ì´ˆê¸°í™”
    qa = RetrievalQA.from_chain_type(
        llm=chat_upstage,
        chain_type="stuff",
        retriever=pinecone_retriever,
        return_source_documents=True,
        chain_type_kwargs={"prompt": custom_prompt}  # ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ ì „ë‹¬
    )

    print(f"User message: {req.message}")
    result = qa(req.message)

    # Retrieve source documents
    source_docs = result['source_documents']

    # Extract content from the source documents
    sources = [{"content": doc.page_content, "metadata": doc.metadata} for doc in source_docs]

    # Log or inspect the retrieved documents
    for i, source in enumerate(sources):
        print(f"Source {i + 1}: {source['content']}")
        print(f"Metadata: {source['metadata']}")

    return {
        "reply": result['result'],
        "sources": sources  # Include source documents in the response
    }

@app.get("/health")
@app.get("/")
async def health_check():
    return {"status": "ok"}


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8000)